{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25abe472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import pathlib\n",
    "from os import path\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979796b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 10\n"
     ]
    }
   ],
   "source": [
    "xls_file_path = \"../output/results.xlsx\"\n",
    "data_df = pd.read_excel(xls_file_path)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "print(f\"Total records: {len(data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ffb5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                   gen_related_work  \\\n",
      "0           0  Related Work\\n\\nThere have been several works ...   \n",
      "1           1  Related Work\\n\\nThere have been several studie...   \n",
      "2           2  Related Work\\n\\nSeveral previous works have fo...   \n",
      "3           3  Related Work\\n\\nSeveral related works have con...   \n",
      "4           4  Related Work\\n\\nNonlinear component analysis t...   \n",
      "5           5  Related Work\\n\\nKnowledge translation (KT) is ...   \n",
      "6           6  Related Work\\n\\nSeveral recent studies have sh...   \n",
      "7           7  Related Work\\n\\nThere have been several studie...   \n",
      "8           8  Related Work\\n\\nSeveral previous algorithms ha...   \n",
      "9           9  Related Work\\n\\nIn recent years, variational i...   \n",
      "\n",
      "                                     gt_related_work  \\\n",
      "0  Existing works on the performance of 802.11 fo...   \n",
      "1  conduct comparative experiments to study the g...   \n",
      "2  XML stream validation is first discussed by Se...   \n",
      "3  This paper is closely related to the following...   \n",
      "4  Many efforts have been devoted to scale up ker...   \n",
      "5  Most transfer learning work focuses on the hom...   \n",
      "6  The skip connections in ResNet are critical si...   \n",
      "7  @cite_4 and Buchbinder, Chen and Naor @cite_0 ...   \n",
      "8  To find a minimum-link path between two points...   \n",
      "9  Our work extends the variational dropout techn...   \n",
      "\n",
      "                                   original_abstract  \\\n",
      "0  Network calculus is a powerful methodology of ...   \n",
      "1  Residual connections significantly boost the p...   \n",
      "2  False-positives are a problem in anomaly-based...   \n",
      "3  Human body part parsing, or human semantic par...   \n",
      "4  Nonlinear component analysis such as kernel Pr...   \n",
      "5  In this paper, we focus on a novel knowledge r...   \n",
      "6  Single image super-resolution (SR) is extremel...   \n",
      "7  Numerous combinatorial optimization problems (...   \n",
      "8  Given a rectilinear domain @math of @math pair...   \n",
      "9  We investigate the use of alternative divergen...   \n",
      "\n",
      "                                           citations  \\\n",
      "0  ['@cite_26', '@cite_21', '@cite_6', '@cite_24'...   \n",
      "1                                       ['@cite_19']   \n",
      "2    ['@cite_35', '@cite_14', '@cite_6', '@cite_12']   \n",
      "3     ['@cite_0', '@cite_4', '@cite_25', '@cite_24']   \n",
      "4  ['@cite_7', '@cite_29', '@cite_32', '@cite_19'...   \n",
      "5                  ['@cite_5', '@cite_6', '@cite_8']   \n",
      "6                 ['@cite_20', '@cite_7', '@cite_2']   \n",
      "7                             ['@cite_0', '@cite_4']   \n",
      "8                                        ['@cite_8']   \n",
      "9                                        ['@cite_0']   \n",
      "\n",
      "                                           abstracts  \n",
      "0  ['', 'We present an analytic model for evaluat...  \n",
      "1  ['In practice it is often found that large ove...  \n",
      "2  ['The exact validation of streaming XML docume...  \n",
      "3  ['Incorporating multi-scale features in fully ...  \n",
      "4  ['Classical methods such as Principal Componen...  \n",
      "5  ['In this paper, we present a new learning sce...  \n",
      "6  ['Recent studies have shown that the performan...  \n",
      "7  ['We provide a framework for designing competi...  \n",
      "8  [\"Given a set of nonintersecting polygonal obs...  \n",
      "9  ['We investigate a local reparameterizaton tec...  \n"
     ]
    }
   ],
   "source": [
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "581044bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36874742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**------------------------- Generated related work -------------------------**\n",
      "Related Work\n",
      "\n",
      "Several related works have contributed to the field of human body part parsing and semantic segmentation using convolutional neural networks (CNNs). In this section, we review some of these works and highlight their significant contributions.\n",
      "\n",
      "One common approach to semantic segmentation is the use of fully convolutional networks (FCNs) [@cite_0]. FCNs have been successful in achieving state-of-the-art performance by incorporating multi-scale features and merging them for pixel-wise classification. The authors propose an attention mechanism that learns to softly weight the multi-scale features at each pixel location. This attention model outperforms average- and max-pooling and allows for the diagnostic visualization of feature importance at different positions and scales. Moreover, they emphasize that adding extra supervision to the output at each scale is crucial for achieving excellent performance when merging multi-scale features. The effectiveness of the proposed model is demonstrated through experiments on challenging datasets, including PASCAL-Person-Part, PASCAL VOC 2012, and a subset of MS-COCO 2014.\n",
      "\n",
      "Atrous convolution, or convolution with upsampled filters, has been identified as a powerful tool in dense prediction tasks [@cite_4]. This technique allows for explicit control over the resolution and enlarges the field of view of filters to incorporate larger context without increasing the number of parameters or computation. To robustly segment objects at multiple scales, the authors propose atrous spatial pyramid pooling (ASPP). ASPP probes convolutional feature layers with filters at multiple sampling rates and effective fields-of-views, capturing objects and image context at various scales. Additionally, the authors combine methods from DCNNs (Deep Convolutional Neural Networks) and probabilistic graphical models to improve the localization of object boundaries. By combining responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), localization performance is shown to be significantly improved. The proposed \"DeepLab\" system achieves state-of-art performance on several benchmark datasets, including PASCAL VOC-2012, PASCAL-Context, PASCAL-Person-Part, and Cityscapes.\n",
      "\n",
      "Another influential work that has contributed to the field of semantic segmentation is the concept of fully convolutional networks (FCNs) [@cite_25]. FCNs take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. The authors adapt contemporary classification networks, such as AlexNet, VGG net, and GoogLeNet, into fully convolutional networks and transfer their learned representations by fine-tuning for the segmentation task. They also introduce a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to achieve accurate and detailed segmentations. The proposed FCN achieves state-of-the-art segmentation performance on various datasets, including PASCAL VOC, NYUDv2, and SIFT Flow.\n",
      "\n",
      "In the context of parsing articulated objects, such as humans and animals, into semantic parts, the Hierarchical Auto-Zoom Net (HAZN) has made significant contributions [@cite_24]. HAZN adapts to the local scales of objects and parts, which is particularly challenging due to the large variability in scale and location. The authors propose a two-stage approach employing fully convolutional networks, the Auto-Zoom Net (AZN), to predict the locations, scales, and part scores of object instances and parts. The model adaptively \"zooms\" (resize) predicted image regions into their proper scales to refine parsing results. Extensive experiments on the PASCAL part datasets on humans, horses, and cows demonstrate the effectiveness of the proposed approach, outperforming state-of-the-art methods and achieving significant improvements in segmenting small instances and small parts.\n",
      "\n",
      "These works form the foundation of human body part parsing and semantic segmentation research using convolutional neural networks. They have pushed the boundaries of performance in this field and provide valuable insights and techniques that can be applied in the proposed method.\n",
      "\n",
      " **------------------------- GT related work -------------------------**\n",
      "This paper is closely related to the following areas: semantic part segmentation, joint pose and body part estimation, and weakly supervised learning. In this subtask of semantic segmentation, fully convolutional network (FCN) @cite_25 and its variants @cite_4 @cite_0 @cite_24 have demonstrated promising results. In @cite_4 , Chen proposed atrous convolution to capture object features at different scales and they further combined the convolutional neural network (CNN) with a Conditional Random Field (CRF) to improve the accuracy. @cite_0 , the authors proposed an attention mechanism that softly combines the segmentation predictions at different scales according to the context. To tackle the problem of scale and location variance, Xia @cite_24 developed a model that adaptively zoom the input image into the proper scale to refine the parsing results.\n"
     ]
    }
   ],
   "source": [
    "print(\"**------------------------- Generated related work -------------------------**\")\n",
    "print(data_df[\"gen_related_work\"][index])\n",
    "print(\"\\n **------------------------- GT related work -------------------------**\")\n",
    "print(data_df[\"gt_related_work\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec5fdf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**------------------------- Original abstract -------------------------**\n",
      "Human body part parsing, or human semantic part segmentation, is fundamental to many computer vision tasks. In conventional semantic segmentation methods, the ground truth segmentations are provided, and fully convolutional networks (FCN) are trained in an end-to-end scheme. Although these methods have demonstrated impressive results, their performance highly depends on the quantity and quality of training data. In this paper, we present a novel method to generate synthetic human part segmentation data using easily-obtained human keypoint annotations. Our key idea is to exploit the anatomical similarity among human to transfer the parsing results of a person to another person with similar pose. Using these estimated results as additional training data, our semi-supervised model outperforms its strong-supervised counterpart by 6 mIOU on the PASCAL-Person-Part dataset, and we achieve state-of-the-art human parsing results. Our approach is general and can be readily extended to other object animal parsing task assuming that their anatomical similarity can be annotated by keypoints. The proposed model and accompanying source code are available at this https URL\n",
      "\n",
      "**------------------------- References ------------------------------**\n",
      "['@cite_0', '@cite_4', '@cite_25', '@cite_24']\n"
     ]
    }
   ],
   "source": [
    "print(\"**------------------------- Original abstract -------------------------**\")\n",
    "print(data_df[\"original_abstract\"][index])\n",
    "print(\"\\n**------------------------- References ------------------------------**\")\n",
    "print(data_df[\"citations\"][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c605791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**------------------------- References abstracts --------------------**\n",
      "['Incorporating multi-scale features in fully convolutional neural networks (FCNs) has been a key element to achieving state-of-the-art performance on semantic image segmentation. One common way to extract multi-scale features is to feed multiple resized input images to a shared deep network and then merge the resulting features for pixelwise classification. In this work, we propose an attention mechanism that learns to softly weight the multi-scale features at each pixel location. We adapt a state-of-the-art semantic image segmentation model, which we jointly train with multi-scale input images and the attention model. The proposed attention model not only outperforms average- and max-pooling, but allows us to diagnostically visualize the importance of features at different positions and scales. Moreover, we show that adding extra supervision to the output at each scale is essential to achieving excellent performance when merging multi-scale features. We demonstrate the effectiveness of our model with extensive experiments on three challenging datasets, including PASCAL-Person-Part, PASCAL VOC 2012 and a subset of MS-COCO 2014.', 'In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or \\'atrous convolution\\', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed \"DeepLab\" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.', 'Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \"fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20 relative improvement to 62.2 mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.', 'Parsing articulated objects, e.g. humans and animals, into semantic parts (e.g. body, head and arms, etc.) from natural images is a challenging and fundamental problem for computer vision. A big difficulty is the large variability of scale and location for objects and their corresponding parts. Even limited mistakes in estimating scale and location will degrade the parsing output and cause errors in boundary details. To tackle these difficulties, we propose a \"Hierarchical Auto-Zoom Net\" (HAZN) for object part parsing which adapts to the local scales of objects and parts. HAZN is a sequence of two \"Auto-Zoom Net\" (AZNs), each employing fully convolutional networks that perform two tasks: (1) predict the locations and scales of object instances (the first AZN) or their parts (the second AZN); (2) estimate the part scores for predicted object instance or part regions. Our model can adaptively \"zoom\" (resize) predicted image regions into their proper scales to refine the parsing. We conduct extensive experiments over the PASCAL part datasets on humans, horses, and cows. For humans, our approach significantly outperforms the state-of-the-arts by 5 mIOU and is especially better at segmenting small instances and small parts. We obtain similar improvements for parsing cows and horses over alternative methods. In summary, our strategy of first zooming into objects and then zooming into parts is very effective. It also enables us to process different regions of the image at different scales adaptively so that, for example, we do not need to waste computational resources scaling the entire image.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n**------------------------- References abstracts --------------------**\")\n",
    "print(data_df[\"abstracts\"][index])\n",
    "# abstract_list = json.load(data_df[\"abstracts\"][index])\n",
    "# print(len(abstract_list))\n",
    "# print(*data_df[\"abstracts\"][index], sep='\\n')\n",
    "# print('\\n'.join(abstract_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d85b0-07f3-41a2-b2d2-cffc782b409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
