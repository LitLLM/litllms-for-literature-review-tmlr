{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from os import path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"results/auto_review/multixscience/gpt-3.5-turo-plan\"\n",
    "model_name = \"gpt-3.5-turo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/colab_public/results/auto_review/multixscience/gpt-3.5-turo-plan/results_gpt-3.5-turo.pkl\n"
     ]
    }
   ],
   "source": [
    "pkl_file_path = path.join(savedir, f\"results_{os.path.split(model_name)[1]}.pkl\")\n",
    "print(pkl_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_load(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl_load(pkl_file_path)\n",
    "result_json = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    You will be provided with an abstract of a sci...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "instruction = result_dataset.text[:1]\n",
    "print(result_dataset.text[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    You will be provided with an abstract of a sci...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(str(instruction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a previous work (@cite_15), the problem of determining when an agent should behave strategically or act as a simple price-taker within an economic Multi-Agent System was addressed. The authors proposed a framework for the incremental implementation of modeling capabilities in agents, along with a description of the forms of knowledge required. They also conducted simulations to study the behavior of different populations of agents and the effectiveness of using and learning agent models. The results showed that savvy buyers can avoid being cheated by sellers and that price volatility can be used to predict the benefits of deeper models. \\n\\nThe field of Artificial Intelligence (AI) has long aimed at creating and understanding intelligence (@cite_6). To bridge the gap between theory and practice, there has been a gradual evolution in the formal conception of intelligence, bringing it closer to the informal conception. This evolution has allowed for the development of robust systems and general results. \\n\\nFurthermore, the work by another group (@cite_9) focused on understanding the behavior of agent populations. They investigated how specific types of agent populations can influence system behavior. This research provides valuable insights into the dynamics of multi-agent systems and can help inform the design and implementation of intelligent agents.\\n\\nOverall, these prior works contribute to the understanding of agent behavior in economic multi-agent systems and the development of intelligent agents. They provide insights into strategic decision-making, the importance of agent models, and the dynamics of agent populations.',\n",
       " 'To address the issue of automating grasping movement in virtual environments, previous work (cite_21) proposed a hybrid approach using forward and inverse kinematics. The authors developed a methodology and algorithm to generate realistic grasping motion of arbitrary shaped objects. They created a database of predefined body postures and hand trajectories which were generalized to adapt to specific grasps. The paper also discussed solutions for common problems in articulated figure animation, such as positioning the body with kinematic constraints and manipulating joint constraints. Additionally, an interpolation algorithm was described to smoothly transition between postures while maintaining feasible joint angles. The results of their approach were satisfactory, as shown in the paper. Our work builds upon this by presenting a visually realistic and flexible grasping system for real-time interactions in virtual environments. We conduct an exhaustive qualitative and quantitative performance analysis to validate our proposal, assessing aspects such as motor control, finger movement realism, and interaction realism. The results of our analysis indicate that previous experience with our grasping system is not necessary for an enjoyable and intuitive VR interaction experience.',\n",
       " 'Previous work has addressed the issue of automating grasping movement in virtual environments. One approach used a hybrid method combining forward and inverse kinematics to generate realistic grasping motion for arbitrary shaped objects (@cite_21). The methodology involved creating a database of predefined body postures and hand trajectories, which could be adapted to specific grasps. The work also addressed problems of articulated figure animation, including kinematic constraints and efficient manipulation of joint constraints. An interpolation algorithm was developed to smoothly transition between postures. The results of the study were deemed satisfactory.',\n",
       " 'Previous studies have focused on analyzing motion coordination patterns and kinematic synergies during manipulative acts in virtual reality (VR) environments (@cite_1). These studies have used motion capture systems to measure joint angles and have employed principal components analysis (PCA) to examine the temporal covariation between joint angles. The results have shown that the angular profiles can be accurately characterized using mathematical modeling procedures. These studies have also revealed stereotypical patterns in the flexion sequence and characteristic interdependence between joints. However, these studies have primarily focused on analyzing hand movements in the physical world and have not specifically addressed the challenges of grasping and manipulating virtual objects in VR environments. Therefore, there is a need for a visually realistic and flexible grasping system that enables real-time interactions in VR environments. This work proposes such a system that automatically fits the hand to the object shape and allows interaction with different objects regardless of their geometries. The proposal has been validated through qualitative and quantitative performance analysis (@cite_28) and the results indicate that previous experience with the grasping system is not required for an enjoyable and intuitive VR interaction experience. The proposed system adds to the existing body of knowledge on motion coordination patterns and kinematic synergies by specifically addressing the challenges of grasping and manipulating virtual objects in VR environments.',\n",
       " 'Previous studies have focused on developing techniques to enhance interaction in virtual reality (VR) environments. For instance, a technique called interaction capture has been proposed to capture contact phenomena and estimate joint compliance without the need for motorized perturbation devices (@cite_11). This technique allows for the synthesis of new interactions through physically based simulation. Additionally, research has been conducted on modifying motion capture to meet the constraints of new animation involving contact, particularly for hands (@cite_11). \\n\\nIn terms of grasping systems, there has been work on developing visually realistic and flexible systems for real-time interactions in virtual environments. One study proposes a grasping system that automatically fits the hand to the object shape based on user input from VR handheld controllers (@cite_26). This system is flexible and can be customized for different hand meshes and object geometries. Another study focuses on the qualitative and quantitative evaluation of a grasping system, assessing aspects such as motor control, finger movement realism, and interaction realism (@cite_29). The results indicate that previous experience with the system is not necessary for an enjoyable and intuitive VR interaction experience. \\n\\nFurthermore, research has been conducted on the analysis and evaluation of performed grips in VR interactions. A novel metric has been proposed to visually analyze the quality of grips (@cite_29). Additionally, studies have explored the compliance of characters during contact in animations, which can provide important insights into the purpose of movement (@cite_11). These studies have used techniques such as position-based linear complementarity problems to model friction, breaking contact, and compliant coupling between contacts at different fingers. \\n\\nIn conclusion, previous work has focused on techniques for capturing contact phenomena, modifying motion capture for animation involving contact, developing visually realistic and flexible grasping systems, and evaluating the quality of grips in VR interactions.',\n",
       " 'Graph Interpolation Grammars (GIGs) are a declarative formalism that aims to replicate key characteristics of the human parser, such as incrementality. GIGs allow for the incremental construction of a syntactic representation of a sentence as each lexeme is processed. The rules in GIGs are partially context-sensitive and reversible, enabling non-deterministic parsing. This expressive power makes GIGs suitable for parsing natural languages. A related work by Brainerd and Rounds explores tree generating systems, which are relevant to GIGs. The paper also discusses the linguistic relevance of these systems (@cite_2).']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_json[\"preds\"][:6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
